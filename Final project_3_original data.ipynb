{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5tjTGRif4Kk"
   },
   "source": [
    "## Spam Filtering\n",
    "In this programming assignment, we will `revisit' Spam Filtering case study with a real data set that has a \"label\" for every email - i.e. spam or not spam. We will try Logistic Regression, Decision Tree and Random Forests. The assignment goes from data loading to data inspection to data pre-processing to creating a train/test data set to finally doing machine learning, making predictions and evaluating it. This is typically one part of the \"full pipeline\" in ML modeling/prototyping - So you will get a sampler taste of some \"prototype pipeline\" work that happens in practice! Have fun!! And if you get stuck somewhere - Use discord - Maybe someone has a suggestion that will unblock you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJxX4po_f4Km"
   },
   "source": [
    "## Loading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "BGWIqvDef4Km"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Winston\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "X2_train = pd.read_csv('X1_train.csv',sep=',',header=None,engine='python',error_bad_lines=False)\n",
    "y2_train = pd.read_csv('y1_train.csv',sep=',',header=None,engine='python',error_bad_lines=False)\n",
    "X2_test = pd.read_csv('X1_test.csv',sep=',',header=None,engine='python',error_bad_lines=False)\n",
    "y2_test = pd.read_csv('y1_test.csv',sep=',',header=None,engine='python',error_bad_lines=False)\n",
    "X2_val = pd.read_csv('X1_val.csv',sep=',',header=None,engine='python',error_bad_lines=False)\n",
    "y2_val = pd.read_csv('y1_val.csv',sep=',',header=None,engine='python',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiX-ojcMf4Kn"
   },
   "source": [
    "## 1. Data Pre-Processing Step\n",
    "Follow data processing steps as in previous HW (HW 5 Part 2) - Feel free to add any processing steps that might help with the new models you will try out in this HW - LR and Random Forest.\n",
    "Also create the train/val/test splits as before (HW 5 part 2) for the emails data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "iALhKGDnf4Ko",
    "outputId": "1c74443f-9ed5-4cdc-c901-bb5b7997c3bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_index</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049781431</td>\n",
       "      <td>@Koppite4004 I always get over-excited when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2186813755</td>\n",
       "      <td>Working on tonight's post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2251415926</td>\n",
       "      <td>Gonna try n fall back 2 sleep! Dream of my &amp;qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2247456751</td>\n",
       "      <td>@danishmarie I remember watching him since ......</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1\n",
       "0  tweet_index                                              tweet\n",
       "1   2049781431  @Koppite4004 I always get over-excited when th...\n",
       "2   2186813755                         Working on tonight's post \n",
       "3   2251415926  Gonna try n fall back 2 sleep! Dream of my &qu...\n",
       "4   2247456751  @danishmarie I remember watching him since ......"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X2_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "JGiC4xbhf4Kp"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "X2_train['tokenized'] = X2_train[1].apply(lambda x: word_tokenize(x))\n",
    "X2_val['tokenized'] = X2_val[1].apply(lambda x: word_tokenize(x))\n",
    "X2_test['tokenized'] = X2_test[1].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "X2_train.to_csv('X2_train_tokenized.cvs')\n",
    "X2_val.to_csv('X2_val_tokenized.cvs')\n",
    "X2_test.to_csv('X2_test_tokenized.cvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "1LkKQenOf4Kp"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "X2_train['filtered_words'] = X2_train['tokenized'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "X2_val['filtered_words'] = X2_val['tokenized'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "X2_test['filtered_words'] = X2_test['tokenized'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "X2_train.to_csv('X2_train_filtered_words.cvs')\n",
    "X2_val.to_csv('X2_val_filtered_words.cvs')\n",
    "X2_test.to_csv('X2_test_filtered_words.cvs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "KDjUNRBBf4Kq"
   },
   "outputs": [],
   "source": [
    "X2_train['new_words'] = X2_train['filtered_words'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "X2_val['new_words'] = X2_val['filtered_words'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "X2_test['new_words'] = X2_test['filtered_words'].apply(lambda x: [word for word in x if word.isalnum()])\n",
    "\n",
    "X2_train.to_csv('X2_train_new_words.cvs')\n",
    "X2_val.to_csv('X2_val_new_words.cvs')\n",
    "X2_test.to_csv('X2_test_new_words.cvs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "bTG8LHv8f4Kq",
    "outputId": "197aa75a-672f-4739-dd2a-43afd11a8b1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>new_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_index</td>\n",
       "      <td>tweet</td>\n",
       "      <td>[tweet]</td>\n",
       "      <td>[tweet]</td>\n",
       "      <td>[tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2048594990</td>\n",
       "      <td>@mantic59 Cool link, but you got an extra T in...</td>\n",
       "      <td>[@, mantic59, Cool, link, ,, but, you, got, an...</td>\n",
       "      <td>[@, mantic59, Cool, link, ,, got, extra, T, ht...</td>\n",
       "      <td>[mantic59, Cool, link, got, extra, T, htttp, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1826490984</td>\n",
       "      <td>@miizluna_jessie tell your mommy i said hiiiii!</td>\n",
       "      <td>[@, miizluna_jessie, tell, your, mommy, i, sai...</td>\n",
       "      <td>[@, miizluna_jessie, tell, mommy, said, hiiiii...</td>\n",
       "      <td>[tell, mommy, said, hiiiii]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014223469</td>\n",
       "      <td>Ten o'clock coffee</td>\n",
       "      <td>[Ten, o'clock, coffee]</td>\n",
       "      <td>[Ten, o'clock, coffee]</td>\n",
       "      <td>[Ten, coffee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2068667671</td>\n",
       "      <td>ive had some food now i have the sneezies  lol</td>\n",
       "      <td>[ive, had, some, food, now, i, have, the, snee...</td>\n",
       "      <td>[ive, food, sneezies, lol]</td>\n",
       "      <td>[ive, food, sneezies, lol]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1  \\\n",
       "0  tweet_index                                              tweet   \n",
       "1   2048594990  @mantic59 Cool link, but you got an extra T in...   \n",
       "2   1826490984   @miizluna_jessie tell your mommy i said hiiiii!    \n",
       "3   2014223469                                Ten o'clock coffee    \n",
       "4   2068667671     ive had some food now i have the sneezies  lol   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                                            [tweet]   \n",
       "1  [@, mantic59, Cool, link, ,, but, you, got, an...   \n",
       "2  [@, miizluna_jessie, tell, your, mommy, i, sai...   \n",
       "3                             [Ten, o'clock, coffee]   \n",
       "4  [ive, had, some, food, now, i, have, the, snee...   \n",
       "\n",
       "                                      filtered_words  \\\n",
       "0                                            [tweet]   \n",
       "1  [@, mantic59, Cool, link, ,, got, extra, T, ht...   \n",
       "2  [@, miizluna_jessie, tell, mommy, said, hiiiii...   \n",
       "3                             [Ten, o'clock, coffee]   \n",
       "4                         [ive, food, sneezies, lol]   \n",
       "\n",
       "                                           new_words  \n",
       "0                                            [tweet]  \n",
       "1  [mantic59, Cool, link, got, extra, T, htttp, p...  \n",
       "2                        [tell, mommy, said, hiiiii]  \n",
       "3                                      [Ten, coffee]  \n",
       "4                         [ive, food, sneezies, lol]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "6XqrS0V-f4Kq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data = X2_train\n",
    "rem_data = X2_train.drop(train_data.index).reset_index(drop=True)\n",
    "val_data = X2_val\n",
    "test_data = X2_test\n",
    "\n",
    "# train_data = data_set.sample(frac=0.8, random_state=25).reset_index(drop=True)\n",
    "# rem_data = data_set.drop(train_data.index).reset_index(drop=True)\n",
    "# val_data = rem_data.sample(frac=0.5, random_state=25).reset_index(drop=True)\n",
    "# test_data = rem_data.drop(val_data.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "IwOiF6i_f4Kr"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['tokenized'], axis = 1)\n",
    "train_data = train_data.drop(['filtered_words'], axis = 1)\n",
    "test_data = test_data.drop(['tokenized'], axis = 1)\n",
    "test_data = test_data.drop(['filtered_words'], axis = 1)\n",
    "val_data = val_data.drop(['tokenized'], axis = 1)\n",
    "val_data = val_data.drop(['filtered_words'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "dnKb-Q_-f4Kr",
    "outputId": "3a8bc358-bd2e-470c-960a-ed5d4684cc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917074, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>new_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_index</td>\n",
       "      <td>tweet</td>\n",
       "      <td>[tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2048594990</td>\n",
       "      <td>@mantic59 Cool link, but you got an extra T in...</td>\n",
       "      <td>[mantic59, Cool, link, got, extra, T, htttp, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1826490984</td>\n",
       "      <td>@miizluna_jessie tell your mommy i said hiiiii!</td>\n",
       "      <td>[tell, mommy, said, hiiiii]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014223469</td>\n",
       "      <td>Ten o'clock coffee</td>\n",
       "      <td>[Ten, coffee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2068667671</td>\n",
       "      <td>ive had some food now i have the sneezies  lol</td>\n",
       "      <td>[ive, food, sneezies, lol]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1  \\\n",
       "0  tweet_index                                              tweet   \n",
       "1   2048594990  @mantic59 Cool link, but you got an extra T in...   \n",
       "2   1826490984   @miizluna_jessie tell your mommy i said hiiiii!    \n",
       "3   2014223469                                Ten o'clock coffee    \n",
       "4   2068667671     ive had some food now i have the sneezies  lol   \n",
       "\n",
       "                                           new_words  \n",
       "0                                            [tweet]  \n",
       "1  [mantic59, Cool, link, got, extra, T, htttp, p...  \n",
       "2                        [tell, mommy, said, hiiiii]  \n",
       "3                                      [Ten, coffee]  \n",
       "4                         [ive, food, sneezies, lol]  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "6R9UTf8Sf4Kr",
    "outputId": "5ea508fb-7020-4c5e-cceb-5a73e8deb21d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131012, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>new_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_index</td>\n",
       "      <td>tweet</td>\n",
       "      <td>[tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2049781431</td>\n",
       "      <td>@Koppite4004 I always get over-excited when th...</td>\n",
       "      <td>[Koppite4004, I, always, get, fixture, lists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2186813755</td>\n",
       "      <td>Working on tonight's post</td>\n",
       "      <td>[Working, tonight, post]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2251415926</td>\n",
       "      <td>Gonna try n fall back 2 sleep! Dream of my &amp;qu...</td>\n",
       "      <td>[Gon, na, try, n, fall, back, 2, sleep, Dream,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2247456751</td>\n",
       "      <td>@danishmarie I remember watching him since ......</td>\n",
       "      <td>[danishmarie, I, remember, watching, since, lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1  \\\n",
       "0  tweet_index                                              tweet   \n",
       "1   2049781431  @Koppite4004 I always get over-excited when th...   \n",
       "2   2186813755                         Working on tonight's post    \n",
       "3   2251415926  Gonna try n fall back 2 sleep! Dream of my &qu...   \n",
       "4   2247456751  @danishmarie I remember watching him since ......   \n",
       "\n",
       "                                           new_words  \n",
       "0                                            [tweet]  \n",
       "1  [Koppite4004, I, always, get, fixture, lists, ...  \n",
       "2                           [Working, tonight, post]  \n",
       "3  [Gon, na, try, n, fall, back, 2, sleep, Dream,...  \n",
       "4  [danishmarie, I, remember, watching, since, lo...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_data.shape)\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yWfWRSX9f4Ks",
    "outputId": "0a217777-3a2e-4e4c-fd7b-d147d70e4667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262023, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>new_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_index</td>\n",
       "      <td>tweet</td>\n",
       "      <td>[tweet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994530242</td>\n",
       "      <td>@bwatwood i'm at the university of central flo...</td>\n",
       "      <td>[bwatwood, university, central, florida, orlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975024899</td>\n",
       "      <td>@LouiseGeek LOL he is class thought cool as Ow...</td>\n",
       "      <td>[LouiseGeek, LOL, class, thought, cool, Owt, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2180684802</td>\n",
       "      <td>@MissChriis saad  i miss you too i'm bored as ...</td>\n",
       "      <td>[MissChriis, saad, miss, bored, hell, got, go,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1684965598</td>\n",
       "      <td>@KarmaElite @dreamsneverend Yeah, but the girl...</td>\n",
       "      <td>[KarmaElite, dreamsneverend, Yeah, girl, playe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                                                  1  \\\n",
       "0  tweet_index                                              tweet   \n",
       "1   1994530242  @bwatwood i'm at the university of central flo...   \n",
       "2   1975024899  @LouiseGeek LOL he is class thought cool as Ow...   \n",
       "3   2180684802  @MissChriis saad  i miss you too i'm bored as ...   \n",
       "4   1684965598  @KarmaElite @dreamsneverend Yeah, but the girl...   \n",
       "\n",
       "                                           new_words  \n",
       "0                                            [tweet]  \n",
       "1  [bwatwood, university, central, florida, orlan...  \n",
       "2  [LouiseGeek, LOL, class, thought, cool, Owt, r...  \n",
       "3  [MissChriis, saad, miss, bored, hell, got, go,...  \n",
       "4  [KarmaElite, dreamsneverend, Yeah, girl, playe...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5NFyjHwf4Ks"
   },
   "source": [
    "## 2. Logistic Regression\n",
    "Below, try out LR with/without regression on spam filtering. Which model gives you best validation error? What role does regularization play here? Which regularizer works best? Which of these models are more interpretable? And how can you see that? Are any of the issues you saw with Naive Bayes method resolved with LR? What are any limitations you see with your LR model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0                                                  1  \\\n",
      "0  tweet_index                                              tweet   \n",
      "1   2048594990  @mantic59 Cool link, but you got an extra T in...   \n",
      "2   1826490984   @miizluna_jessie tell your mommy i said hiiiii!    \n",
      "3   2014223469                                Ten o'clock coffee    \n",
      "4   2068667671     ive had some food now i have the sneezies  lol   \n",
      "\n",
      "                                           tokenized  \\\n",
      "0                                            [tweet]   \n",
      "1  [@, mantic59, Cool, link, ,, but, you, got, an...   \n",
      "2  [@, miizluna_jessie, tell, your, mommy, i, sai...   \n",
      "3                             [Ten, o'clock, coffee]   \n",
      "4  [ive, had, some, food, now, i, have, the, snee...   \n",
      "\n",
      "                                      filtered_words  \\\n",
      "0                                            [tweet]   \n",
      "1  [@, mantic59, Cool, link, ,, got, extra, T, ht...   \n",
      "2  [@, miizluna_jessie, tell, mommy, said, hiiiii...   \n",
      "3                             [Ten, o'clock, coffee]   \n",
      "4                         [ive, food, sneezies, lol]   \n",
      "\n",
      "                                           new_words  \n",
      "0                                            [tweet]  \n",
      "1  [mantic59, Cool, link, got, extra, T, htttp, p...  \n",
      "2                        [tell, mommy, said, hiiiii]  \n",
      "3                                      [Ten, coffee]  \n",
      "4                         [ive, food, sneezies, lol]  \n"
     ]
    }
   ],
   "source": [
    "print(X2_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "HwIHx8_Uf4Ks"
   },
   "outputs": [],
   "source": [
    "# Your code here for LR with and without regularization \n",
    "# including obtaining validation errors.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y_train = y2_train[1]\n",
    "y_test = y2_test[1]\n",
    "y_val = y2_val[1]\n",
    "\n",
    "cv = CountVectorizer(binary=False, max_df=0.95) \n",
    "cv.fit(train_data[1]) # To get a dictionary\n",
    "train_feature_set = cv.transform(train_data[1])\n",
    "test_feature_set = cv.transform(test_data[1])\n",
    "val_feature_set = cv.transform(val_data[1])\n",
    "\n",
    "def LR():\n",
    "    clf = LogisticRegression(solver='saga')\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    print('Results of LR')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df1 = pd.DataFrame(X2_val)\n",
    "    df1['Prediction'] = pred\n",
    "    df1 = df1.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df1.to_csv('LRout.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')\n",
    "\n",
    "def LR_Regularized():\n",
    "    clf = LogisticRegression(solver='liblinear', penalty = 'l1')\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of LR_Regularized')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df2 = pd.DataFrame(X2_val)\n",
    "    df2['Prediction'] = pred\n",
    "    df2 = df2.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df2.to_csv('LR_Reg_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')\n",
    "\n",
    "def LR_best_hyperparam():\n",
    "    clf = LogisticRegression(solver='liblinear', penalty = 'l2')\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of LR_best_hyperparam')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df3 = pd.DataFrame(X2_val)\n",
    "    df3['Prediction'] = pred\n",
    "    df3 = df3.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df3.to_csv('LR_best_hyper_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "uFvUkUOWf4Kt",
    "outputId": "45eb9027-078c-4df1-f6ad-6d52d273fdea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Winston\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of LR\n",
      "Accuracy:  0.7970033279394254\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "BLXvBlRof4Kt",
    "outputId": "a7421842-cbde-4326-c955-e7211c75aa9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of LR_Regularized\n",
      "Accuracy:  0.7965987848441364\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "LR_Regularized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "zREyQoF0f4Ku",
    "outputId": "57d8ac67-3d48-4b6d-fcd5-6089896c70ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of LR_best_hyperparam\n",
      "Accuracy:  0.7965835190669557\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "LR_best_hyperparam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrNtTl9sf4Ku"
   },
   "source": [
    "## 3. Decision Tree\n",
    "Train a DT on the same data set. Let depth of the tree be a hyper-param. Which depth gives you the best validation error? What are the top 20 features as per the DT? How do they compare to the top 20 features from LR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "s0z4IlBxf4Ku"
   },
   "outputs": [],
   "source": [
    "# Your code here for DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def DT():\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of DT')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df4 = pd.DataFrame(X2_val)\n",
    "    df4['Prediction'] = pred\n",
    "    df4 = df4.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df4.to_csv('DT_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')\n",
    "    \n",
    "def DT_best_tree_depth():\n",
    "    clf = DecisionTreeClassifier(max_depth=60)\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of DT_best_tree_depth')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df5 = pd.DataFrame(X2_val)\n",
    "    df5['Prediction'] = pred\n",
    "    df5 = df5.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df5.to_csv('DT_best_tree_depth_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "-CmkstKxf4Kv",
    "outputId": "22d421bf-682d-4e2b-e42f-af6aea200838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of DT\n",
      "Accuracy:  0.7300781607791653\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "DT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "6pKT1Om2f4Kv",
    "outputId": "bfb6473c-ff90-4629-afa8-d81b8139b813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of DT_best_tree_depth\n",
      "Accuracy:  0.7079962140872592\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "DT_best_tree_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNl34r34f4Kv"
   },
   "source": [
    "## 4. Random Forests\n",
    "To improve upon DTs you decide to implement a Random Forest. The hyper-params are number of DTs and depth per tree. How does the performance of Random Forest compare against the DT you trained earlier. How does the validation error compare? Also how do the precision/recall compare between DT and Random Forest on test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "vFGokKcKf4Kw"
   },
   "outputs": [],
   "source": [
    "# Your code here for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest():\n",
    "    clf = RandomForestClassifier(max_depth = 1)\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of Random Forest')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df6 = pd.DataFrame(X2_val)\n",
    "    df6['Prediction'] = pred\n",
    "    df6 = df6.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df6.to_csv('random_forest_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')\n",
    "    \n",
    "\n",
    "def random_forest_hyperparam_tuning():\n",
    "    clf = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(val_feature_set)\n",
    "    \n",
    "    print('Results of Random Forest')\n",
    "    print('Accuracy: ', accuracy_score(y_val, pred))\n",
    "    \n",
    "    print('aaaa')\n",
    "    df7 = pd.DataFrame(X2_val)\n",
    "    df7['Prediction'] = pred\n",
    "    df7 = df7.set_axis(['a', 'b','c','d','e','Prediction'], axis=1, inplace=False)\n",
    "    #print(df)\n",
    "    header = [\"a\", \"Prediction\"]\n",
    "    df7.to_csv('random_forest_out.csv', columns = header, header=False,index=False)\n",
    "    print('aaaa')\n",
    "\n",
    "def precision_recall_trees():\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(test_feature_set)\n",
    "    \n",
    "    print('Results of DT')\n",
    "    print('Precision: ', precision_score(y_test, pred, average='micro'))\n",
    "    print('Recall: ', recall_score(y_test, pred, average='micro'))\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth = 1)\n",
    "    clf.fit(train_feature_set, y_train)\n",
    "    pred = clf.predict(test_feature_set)\n",
    "    \n",
    "    print('\\nResults of Random Forest')\n",
    "    print('Precision: ', precision_score(y_test, pred, average='micro'))\n",
    "    print('Recall: ', recall_score(y_test, pred, average='micro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "FHChjb1vf4Kw",
    "outputId": "e4c8a06b-5b35-4780-aea9-3594b3528651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Random Forest\n",
      "Accuracy:  0.58248099410741\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "rAf16VRqf4Kw",
    "outputId": "dc155885-3024-4183-9dc4-6b50b89f741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Random Forest\n",
      "Accuracy:  0.715132964919244\n",
      "aaaa\n",
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "random_forest_hyperparam_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "avsgKc-Of4Kw",
    "outputId": "51c24a2e-e94f-43a0-82e2-378660b61ab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of DT\n",
      "Precision:  0.7298405101842205\n",
      "Recall:  0.7298405101842205\n",
      "\n",
      "Results of Random Forest\n",
      "Precision:  0.5815291024070406\n",
      "Recall:  0.5815291024070406\n"
     ]
    }
   ],
   "source": [
    "precision_recall_trees()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrYw6z--f4Kw"
   },
   "source": [
    "## 5. Overall\n",
    "What are your insights from training these models? Which models are good at what? Which ML model would you use in practice for spam filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqzjaIFlf4Kx"
   },
   "source": [
    "I would use Logistic Regression as they yield better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW6_Part2_Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
